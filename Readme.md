# ğŸ“Š AnÃ¡lise EstratÃ©gica de CobranÃ§a com Power BI + Modelos Preditivos

Este projeto simula uma base de dados de inadimplÃªncia para construÃ§Ã£o de um **dashboard estratÃ©gico de cobranÃ§a**, com o objetivo de identificar os canais mais eficazes, o melhor momento para abordagem e o perfil de risco dos devedores. A soluÃ§Ã£o final foi construÃ­da utilizando **Python**, **Power BI** e tÃ©cnicas de **Machine Learning**, com foco em **decisÃ£o de negÃ³cio orientada a dados**.

---

## ğŸ“Œ Objetivo

Desenvolver um painel analÃ­tico e modelos preditivos que auxiliem equipes de cobranÃ§a a:
- Identificar os **canais mais efetivos**
- Entender **qual faixa de atraso gera maior resposta**
- Avaliar a **distribuiÃ§Ã£o da dÃ­vida por risco**
- Prever **clientes com maior probabilidade de responder positivamente Ã  cobranÃ§a**

> âš ï¸ **Nota Importante**: Os modelos preditivos aqui desenvolvidos apresentaram desempenho prÃ³ximo ao acaso (AUC em torno de 0.56â€“0.60). Isso indica **limitaÃ§Ãµes nas variÃ¡veis disponÃ­veis** para previsÃ£o efetiva do comportamento de pagamento. Para aplicaÃ§Ã£o prÃ¡tica em estratÃ©gias de cobranÃ§a, seria necessÃ¡ria a inclusÃ£o de dados adicionais como:
> - HistÃ³rico real de pagamentos
> - NÃºmero e tipo de interaÃ§Ãµes prÃ©vias
> - Promessas quebradas
> - Tempo mÃ©dio de resposta
> - AnÃ¡lise de sentimento nas mensagens

---

## ğŸ› ï¸ Ferramentas Utilizadas

### Linguagens e Frameworks
- **Python 3.11+**: Linguagem principal para processamento de dados e ML
- **pandas**: ManipulaÃ§Ã£o e anÃ¡lise de dados
- **scikit-learn**: ImplementaÃ§Ã£o de algoritmos de machine learning
- **XGBoost**: Algoritmo de gradient boosting para classificaÃ§Ã£o
- **matplotlib**: VisualizaÃ§Ã£o de dados e mÃ©tricas de modelo

### Ferramentas de BI e VisualizaÃ§Ã£o
- **Power BI Desktop**: Dashboard interativo e storytelling analÃ­tico
- **Power Query**: TransformaÃ§Ã£o e limpeza de dados
- **Excel**: Ajustes finais e validaÃ§Ã£o de dados

### Infraestrutura de Dados
- **CSV**: Formato de armazenamento para dados estruturados
- **joblib**: SerializaÃ§Ã£o e persistÃªncia de modelos treinados
- **Pipeline sklearn**: OrquestraÃ§Ã£o de prÃ©-processamento e modelagem

---

## ğŸ“ Estrutura do Projeto

```
projeto-cobranca-python-powerbi/
â”œâ”€â”€ ğŸ“ data/                              # Dados processados e transformados
â”‚   â”œâ”€â”€ clientes_enriquecido.csv         # Dataset principal com features engenheiradas
â”‚   â”œâ”€â”€ X_treino.csv                     # Features de treino (dados originais)
â”‚   â”œâ”€â”€ X_teste.csv                      # Features de teste (dados originais)
â”‚   â”œâ”€â”€ X_treino_transformado.csv        # Features de treino (pÃ³s one-hot encoding)
â”‚   â”œâ”€â”€ X_teste_transformado.csv         # Features de teste (pÃ³s one-hot encoding)
â”‚   â”œâ”€â”€ y_treino.csv                     # Target de treino
â”‚   â””â”€â”€ y_teste.csv                      # Target de teste
â”œâ”€â”€ ğŸ“ scripts/                          # Scripts Python para processamento e ML
â”‚   â”œâ”€â”€ gerar_base.py                    # GeraÃ§Ã£o de dados sintÃ©ticos
â”‚   â”œâ”€â”€ analise_dados.py                 # Feature engineering e enriquecimento
â”‚   â”œâ”€â”€ pipeline_etl.py                  # Pipeline de ETL e prÃ©-processamento
â”‚   â”œâ”€â”€ regressao_logistica.py           # Modelo de regressÃ£o logÃ­stica
â”‚   â”œâ”€â”€ random_forest.py                 # Modelo Random Forest
â”‚   â””â”€â”€ modelo_xgboost.py                # Modelo XGBoost
â”œâ”€â”€ ğŸ“ modelo_regressao_logistica/       # Artefatos do modelo de regressÃ£o logÃ­stica
â”‚   â”œâ”€â”€ modelo.pkl                       # Modelo serializado
â”‚   â”œâ”€â”€ matriz_confusao.png              # Matriz de confusÃ£o
â”‚   â”œâ”€â”€ curva_roc.png                    # Curva ROC
â”‚   â”œâ”€â”€ impacto_features.csv             # ImportÃ¢ncia das features
â”‚   â””â”€â”€ coeficientes_impacto_features.png # VisualizaÃ§Ã£o dos coeficientes
â”œâ”€â”€ ğŸ“ modelo_random_forest/             # Artefatos do modelo Random Forest
â”‚   â”œâ”€â”€ modelo.pkl                       # Modelo serializado
â”‚   â”œâ”€â”€ matriz_confusao.png              # Matriz de confusÃ£o
â”‚   â”œâ”€â”€ curva_roc.png                    # Curva ROC
â”‚   â”œâ”€â”€ impacto_features.csv             # ImportÃ¢ncia das features (Gini)
â”‚   â””â”€â”€ GINI_impacto_features.png        # VisualizaÃ§Ã£o da importÃ¢ncia
â”œâ”€â”€ ğŸ“ modelo_xgboost/                   # Artefatos do modelo XGBoost
â”‚   â”œâ”€â”€ modelo.pkl                       # Modelo serializado
â”‚   â”œâ”€â”€ matriz_confusao.png              # Matriz de confusÃ£o
â”‚   â”œâ”€â”€ curva_roc.png                    # Curva ROC
â”‚   â”œâ”€â”€ impacto_features.csv             # ImportÃ¢ncia das features (Gain)
â”‚   â””â”€â”€ GAIN_impacto_features.png        # VisualizaÃ§Ã£o da importÃ¢ncia
â”œâ”€â”€ ğŸ“ imagens/                          # Assets visuais do dashboard
â”‚   â”œâ”€â”€ img_dashboard.png                # Screenshot do dashboard principal
â”‚   â””â”€â”€ img_resumo.png                   # Screenshot da pÃ¡gina de resumo
â”œâ”€â”€ ğŸ“„ painel.pbix                       # Arquivo do Power BI
â”œâ”€â”€ ğŸ“„ requirements.txt                  # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ .gitignore                        # Arquivos ignorados pelo Git
â””â”€â”€ ğŸ“„ README.md                         # DocumentaÃ§Ã£o do projeto
```

---

### Fluxo de Dados

O projeto segue um pipeline estruturado de processamento de dados:

1. **GeraÃ§Ã£o de Dados SintÃ©ticos** (`gerar_base.py`)
   - Simula base realÃ­stica de inadimplÃªncia com 250 registros
   - Inclui variÃ¡veis como nome, dias em atraso, valor da dÃ­vida, canal utilizado, resposta do cliente e faixa de risco

2. **Feature Engineering** (`analise_dados.py`)
   - CriaÃ§Ã£o de faixas de atraso categÃ³ricas
   - BinarizaÃ§Ã£o de respostas positivas
   - Agrupamento de canais (Digital vs Humano)
   - CategorizaÃ§Ã£o de valores em faixas

3. **Pipeline ETL** (`pipeline_etl.py`)
   - SeparaÃ§Ã£o treino/teste estratificada (70/30)
   - One-hot encoding para variÃ¡veis categÃ³ricas
   - Tratamento de valores ausentes
   - PadronizaÃ§Ã£o de features numÃ©ricas

4. **Modelagem Preditiva** (mÃºltiplos scripts)
   - Treinamento de trÃªs algoritmos diferentes
   - AvaliaÃ§Ã£o comparativa de performance
   - GeraÃ§Ã£o de mÃ©tricas e visualizaÃ§Ãµes

5. **VisualizaÃ§Ã£o e BI** (Power BI)
   - Dashboard interativo com KPIs principais
   - AnÃ¡lise exploratÃ³ria por segmentos
   - Storytelling analÃ­tico para tomada de decisÃ£o
   
---

## ğŸ“‰ Modelos Preditivos Aplicados

### ğŸ”¹ RegressÃ£o LogÃ­stica

- InterpretaÃ§Ã£o baseada em **coeficientes log-odds** (direcional)
- Score: AUC = 0.56

**ğŸ“Š GrÃ¡ficos:**
- ![Curva ROC - RegressÃ£o LogÃ­stica](modelo_regressao_logistica/curva_roc.png)
- ![Matriz de ConfusÃ£o - RegressÃ£o LogÃ­stica](modelo_regressao_logistica/matriz_confusao.png)
- ![Impacto - Coeficientes](modelo_regressao_logistica/coeficientes_impacto_features.png)

---

### ğŸ”¹ Random Forest

- ImportÃ¢ncia medida por **Gini Importance**
- Score: AUC = 0.60

**ğŸ“Š GrÃ¡ficos:**
- ![Curva ROC - Random Forest](modelo_random_forest/curva_roc.png)
- ![Matriz de ConfusÃ£o - Random Forest](modelo_random_forest/matriz_confusao.png)
- ![ImportÃ¢ncia - Gini](modelo_random_forest/GINI_impacto_features.png)

---

### ğŸ”¹ XGBoost

- ImportÃ¢ncia medida por **Gain** (aumento mÃ©dio no split)
- Score: AUC = 0.56

**ğŸ“Š GrÃ¡ficos:**
- ![Curva ROC - XGBoost](modelo_xgboost/curva_roc.png)
- ![Matriz de ConfusÃ£o - XGBoost](modelo_xgboost/matriz_confusao.png)
- ![ImportÃ¢ncia - Gain](modelo_xgboost/GAIN_impacto_features.png)

**ğŸ“Š Comparativo de Performance dos Modelos**

Modelo	AUC-ROC	F1-Score	PrecisÃ£o	Recall
RegressÃ£o LogÃ­stica	0.56	0.50	0.50	0.50
Random Forest	0.60	0.50	0.50	0.50
XGBoost	0.56	0.52	0.53	0.53

ğŸ“Œ InterpretaÃ§Ã£o EstratÃ©gica
Random Forest obteve o maior AUC-ROC (0.60), sugerindo leve vantagem na separaÃ§Ã£o de inadimplentes.

XGBoost apresentou melhor equilÃ­brio entre precisÃ£o, recall e F1-score.

Todos os modelos ficaram prÃ³ximos do limiar aleatÃ³rio (AUC ~0.5), indicando que a base atual nÃ£o possui variÃ¡veis suficientes para generalizar padrÃµes de inadimplÃªncia com confianÃ§a.

Apesar da performance fraca, a estrutura do pipeline e os testes comparativos representam uma prova de conceito sÃ³lida. Com dados adicionais (ex: histÃ³rico de pagamento, tempo de resposta, tentativas de contato, etc.), o modelo pode se tornar viÃ¡vel para orientar estratÃ©gias de cobranÃ§a reais.

ğŸ“Œ ConclusÃ£o:
Embora os modelos tenham sido implementados corretamente, seus resultados evidenciam a necessidade de enriquecimento de dados para aumentar o poder preditivo. Eles sÃ£o Ãºteis como prova de conceito, mas ainda nÃ£o sÃ£o confiÃ¡veis para orientar decisÃµes reais de cobranÃ§a.

---

## ğŸ“ˆ Visual do Painel no Power BI

### PÃ¡gina 1 â€“ Dashboard Interativo

![Dashboard](imagens/img_dashboard.png)

### PÃ¡gina 2 â€“ Resumo EstratÃ©gico

![Resumo](imagens/img_resumo.png)

---

## ğŸ“Œ Destaques EstratÃ©gicos

- A **Assessoria** apresenta a **maior taxa de resposta** (59%), sendo o canal mais eficaz para recuperaÃ§Ã£o.
- O intervalo de **30 a 60 dias de atraso** tem a **melhor resposta mÃ©dia** (61%).
- Clientes de **Risco Muito Alto** concentram mais de **60% da dÃ­vida total**.

---

## ğŸ‘¨â€ğŸ’» Autor

**Matheus Nunes Cardoso**  
ğŸ“§ Email: mtsnunescardoso@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/matheus-nunes-cardoso-3b3635186)

---

## ğŸ“ LicenÃ§a

Este projeto Ã© de uso livre para fins educacionais e demonstraÃ§Ã£o profissional.
